# Signal/Noise PRD (Living Document)

**Objective:** Build a pipeline to Ingest → Segment → Save → Review → Label → Search audio and text content, culminating in structured Topic analysis and Analyst POVs.

## 1. Core Data Model

### Segments
- **Definition:** Atomic units of content (text/audio clips).
- **Key Fields:** `document_id`, `text`, `start_offset`, `end_offset`, `segment_status`.

### Topics (New Architecture)
- **`topic_ids`**: The evergreen identity of a topic (e.g., "AI Safety").
- **`topics_history`**: The mutable log of a topic's understanding.
    - `topic_id`: Reference to the evergreen ID.
    - `segment_id`: The segment that triggered this update.
    - `name`, `description`: Evolving definition.
    - `user_hypothesis`: The user's angle/question.
    - `summary_text`: The AI's analysis of how the segment impacts the hypothesis (Confirms/Refutes).
- **`persona_topic_povs`**: Synthesized high-level views generated by "Analyst" agents based on topic history.

## 2. Functional Requirements

### Phase 1: Ingestion & Segmentation (Completed)
- Ingest generic RSS feeds (Podcasts) and web pages (Stratechery).
- Transcribe audio to text (OpenAI/AssemblyAI).
- Store raw documents and enable manual segmentation (defining start/end points).
- **Segmentation Workbench:** Interactive UI for selecting text from HTML documents and creating segments with accurate HTML extraction using `find_html_fragment`.
- **Document Management:** Archive functionality to remove documents from active view.
- **Source Refresh:** Queue-based ingestion system for refreshing selected sources.

### Phase 2: Analysis Workflow (Completed - MVP)
- **User Interface:** Next.js application replacing Retool.
- **Workflow:**
    1. **Select Segment:** User picks a segment from the queue.
    2. **Topic Association:**
        - System suggests existing relevant topics.
        - System generates *new* potential topics.
        - User can manually create topics.
    3. **Hypothesis Testing:**
        - User drafts a hypothesis (e.g., "Google is losing the AI race").
        - System checks segment text against hypothesis ("Refuted: Google's new model beats benchmarks").
    4. **Refinement & Save:**
        - User edits the Topic Name, Description, and Analysis using Markdown.
        - User selects which topics to save using checkboxes.
        - Saving writes a new immutable record to `topics_history`.
- **Segmentation Workflow:**
    1. Navigate to document from Documents page.
    2. Click "Segment" button to open Segmentation Workbench.
    3. Select text in HTML viewer (selection persists visually).
    4. Click "Create Segment" to extract HTML and create segment entry.
    5. View existing segments in compact table above document content.

### Phase 3: Synthesis (Pending/Next)
- **Analyst POV Agent:**
    - Input: A Topic's history (all segments and analyses).
    - Output: A cohesive "Point of View" summary.
    - Status: Endpoint exists (`POST /analysis:generate_pov`), logic is placeholder.

## 3. Technical Stack
- **Backend:** Python (FastAPI), Supabase (PostgreSQL + `pgvector` for future search).
- **Frontend:** Next.js (React), Tailwind CSS.
- **AI/ML:** OpenAI GPT-4o (via LangChain/LangGraph) for suggestions and analysis.

## 4. Design Guidelines
- **Navigation:** Simple top-bar navigation (Segments | Topics | Documents | Sources).
- **Styling:** Clean, text-heavy interface. High contrast (black text on white).
- **Interactivity:**
    - Markdown editors for rich text.
    - "Check Hypothesis" provides immediate feedback loops.
